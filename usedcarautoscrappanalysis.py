# -*- coding: utf-8 -*-
"""UsedCarAutoScrappAnalysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q8tbgtN06NE0vDMHVlcBCZfm8riQlBE1
"""

!pip install requests beautifulsoup4
!pip install google-colab-selenium

"""# Avec Selenium with multiple Pages involved"""

#1nl, pas sur que ce soit utile....
#!chmod +x /content/chromedriver

from selenium import webdriver
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager
import csv
import time
import pandas as pd

# Data storage setup
data = pd.DataFrame([], columns=['car', 'model', 'caract', 'price'])

# Setting up Chrome options for Selenium
options = webdriver.ChromeOptions()
options.add_argument("--headless")  # Run in background
options.add_argument("start-maximized")
options.add_argument("disable-infobars")
options.add_argument("--disable-extensions")
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")


import google_colab_selenium as gs

driver = gs.Chrome()

# URL setup and CSV file configuration
url_base = "https://www.autosphere.fr/recherche?"

with open('carsApril2024.csv', 'w', newline='', encoding='utf-8') as file:
    writer = csv.writer(file)
    writer.writerow(['Title', 'Price'])

    for page in range(1, 3):
        url = f"{url_base}&page={page}"
        driver.get(url)

        # Pause to ensure the page loads
        time.sleep(3)  # Adjust timing based on the server response time and page complexity

        # Extracting car data using Selenium
        cars = driver.find_elements(By.CLASS_NAME, 'bloc_infos_veh_parent')

        for car in cars:
            try:
                title = car.find_element(By.CLASS_NAME, 'marque').text
                modele = car.find_element(By.CLASS_NAME, 'modele').text
                caract = car.find_element(By.CLASS_NAME, 'caract').text
                price = car.find_element(By.CLASS_NAME, 'bloc_prix').text
                writer.writerow([title,modele,caract, price])
                # Print or store the data as needed
                data.loc[-1] = [title, modele, caract, price]  # adding a row
                data.index = data.index + 1  # shifting index
                data = data.sort_index()  # sorting by index
            except Exception as e:
                print(f"Failed to retrieve some data for a car: {str(e)}")

# Quit the driver to free resources
driver.quit()

"""# Avec BeautifulSoup  ( et Ã§a marche bien!!)"""

import requests
from bs4 import BeautifulSoup
import csv
import random
import time

import pandas as pd
data = pd.DataFrame([],columns=['car','model','caract','price'])

# Explicitly disable proxies by setting them to None
session = requests.Session()
session.proxies = {"http": None, "https": None}

# Headers with a common user agent
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.9',
    'Referer': 'https://www.google.com/'
}
session.headers.update(headers)

# URL setup and CSV file configuration
url_base = "https://www.autosphere.fr/recherche?"

with open('carsApril.csv', 'w', newline='', encoding='utf-8') as file:
    writer = csv.writer(file)
    writer.writerow(['Title', 'Price'])

    for page in range(1, 3):
        url = f"{url_base}&page={page}"
        response = session.get(url)

        if response.status_code == 200:
            print(f"Page {page} retrieved successfully!")
            soup = BeautifulSoup(response.text, 'html.parser')
            cars = soup.find_all('div', class_='bloc_infos_veh_parent')

            for car in cars:
                try:
                    title = car.find('span', class_='marque').get_text(strip=True)
                    modele = car.find('span', class_='modele').get_text(strip=True)
                    caract= car.find('div', class_='caract').get_text(strip=True)
                    price = car.find('span', class_='bloc_prix').get_text(strip=True)
                    writer.writerow([title,modele,caract, price])
                    #print(f"Car: {title} {modele} {caract}- Price: {price}")
                    data.loc[-1] = [title, modele, caract,price]  # adding a row
                    data.index = data.index + 1  # shifting index
                    data = data.sort_index()  # sorting by index
                except AttributeError as e:
                    print(f"Failed to retrieve some data for a car: {str(e)}")
        else:
            print(f"Failed to retrieve page {page}, status code: {response.status_code}")

        time.sleep(random.randint(1, 3))  # Avoid hitting the server too rapidly

data

"""# To send an email when over"""

# Commented out IPython magic to ensure Python compatibility.
# Import Python Packages
import smtplib
# Set Global Variables
gmail_user = 'YOUR EMAIL'
gmail_password = 'YOUR PASSWORD'
# Create Email
mail_from = gmail_user
mail_to = 'DESTINATOR EMAIL'
mail_subject = 'Hello'
mail_message_body = 'Hello World!'

mail_message = '''\
From: %s
To: %s
Subject: %s
# %s
''' % (mail_from, mail_to, mail_subject, mail_message_body)
# Sent Email
server = smtplib.SMTP_SSL('smtp.gmail.com', 465)
server.login(gmail_user, gmail_password)
server.sendmail(mail_from, mail_to, mail_message)
server.close()

